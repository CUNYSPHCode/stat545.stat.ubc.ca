---
title: "Lecture Notes: The Model-Fitting Paradigm in R"
subtitle: "Version 1.0.0"
output: html_document
---

```{r, echo = FALSE, message = FALSE, warning = FALSE, results = "asis"}
knitr::opts_chunk$set(fig.width = 5, fig.height = 3, 
                      fig.align = "center", error = TRUE)
```


## Learning Objectives

From today's class, students are anticipated to be able to:

- make a model object in R, using `lm()` as an example.
- write a formula in R.
- predict on a model object with the `broom::augment()` and `predict()` functions.
- extract information from a model object using `broom::tidy()`, `broom::glance()`, and traditional means.


## Resources

Video lecture:

- [The Model-Fitting Paradigm in R](https://youtu.be/jQqCDeJYzao)

Other resources, in addition to the notes below:

- The [broom vignette](https://cran.r-project.org/web/packages/broom/vignettes/broom.html) is useful for learning the details of broom, a package for tidying the output of models.
- If you want a quick intro to linear regression with R, check out this [U Chicago Tutorial](https://cfss.uchicago.edu/notes/linear-models/) on model fitting in R (just the linear regression part).
- If you're eager to learn more about models in general, [An Introduction to Statistical Learning](https://www-bcf.usc.edu/~gareth/ISL/) is an approachable read (the book is freely available online)
- [Mike Marin's R playlist on YouTube](https://www.youtube.com/playlist?list=PLqzoL9-eJTNBlVXxWvJkq0dtVut2sICUW) helps you use R to obtain statistical results. 

## Test Your Understanding

1. TRUE or FALSE: the output of `glance` on the above returns only 1 row because there is only 1 explanatory variable in the model.
2. TRUE or FALSE: the output of `broom::tidy()` package is more "tidy"  than `coef(summary())` because the output is a `tibble`
3. TRUE or FALSE: We need to use a modelling function, such as `lm`, before we can graph a fitted line with `geom_smooth`.
4. TRUE or FALSE: If I wanted to find the amount that `lifeExp` changes per `year`, then I need to use `broom::tidy()`

# Vincenzo's Notes

Data wrangling and plotting can get you pretty far when it comes to drawing insight from your data. But, sometimes you need to go further. For example:

- Investigate the relationship between two or more variables
- Predict the outcome of a variable given information about other variables
- Get evidence towards a hypothesis through a hypothesis test.

These all involve fitting models -- or at least, involve performing more advanced computations than can be done with tidyverse packages like dplyr.

In this tutorial, we'll cover:

1. how a model is typically fit in R;
2. how to extract information from the model after fitting it, using the `broom` package; or,
3. extract information by other means if the `broom` package is not set up for your model. 

This tutorial is _not_ about the specifics of fitting a model. Even though a few references to statistical concepts are made, just take these for face value. 

## Example: linear model

Here are a couple tasks that model-fitting would be useful to address. 

1. A car weighs 4000 lbs. Provide a numerical prediction on its mpg (miles per gallon). 
2. Does the weight of a car influence its mpg?
3. How many more miles per gallon can we expect of a car that weighs 1000 lbs less than another car?

A simple scatterplot will give us a general idea, but can't give us specifics. Here, we use the `mtcars` dataset in the `datasets` package. A linear model is one example of a model that can attempt to answer all three -- the line corresponding to the fitted model has been added to the scatterplot.

```{r, fig.width = 5, fig.height = 3, echo = FALSE, message = FALSE}
ggplot(mtcars, aes(wt, mpg)) +
  geom_point() +
  labs(x = "Weight (1000's of lbs)") +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() 
fit <- lm(mpg ~ wt, data = mtcars)
```

(By the way, you can plot the model using `ggplot2`'s `geom_smooth()` layer -- but you can't interact with the model downstream.)

We can make a prediction of mpg for a car weighing 3,000 lbs by evaluating the line at X = 3:

```{r, echo = FALSE}
predict(fit, newdata = tibble(wt = 3)) %>% 
  unname()
```

We can find the p-value testing the null hypothesis that the true slope of the regression line is 0:

```{r, echo = FALSE}
glance(fit)$p.value %>% 
  unname()
```

And we can calculate how many more miles per gallon a car weighing 1000 less lbs would be expected to have through the slope:

```{r, echo = FALSE}
-tidy(fit)$estimate[2]
```


## Fitting a model in R

Fitting a model in R typically involves using a function in the following format:

```
method(formula, data, options)
```

__Method__:

A function such as:

- Linear Regression: `lm`
- Generalized Linear Regression: `glm`
- Local regression: `loess`
- Quantile regression: `quantreg::rq`
- ...

__Formula__:

In R, takes the form `y ~ x1 + x2 + ... + xp` (use column names in your data frame), where `y` here means the outcome variable you're interested in viewing in relation to other variables `x1`, `x2`, ...

__Data__: The data frame or tibble.

__Options__: Specific to the method.

Running the code returns an object that you can then work with to extract results. 

For example, let's fit a linear regression model on a car's mileage per gallon (`mpg`, "Y" variable) from the car's weight (`wt`, "X" variable). Notice that no special options are needed for `lm()`.

```{r}
(my_lm <- lm(mpg ~ wt, data = mtcars))
```

Printing the model to the screen might lead you to incorrectly conclude that the model object `my_lm` only contains the above text. The reality is, `my_lm` contains a lot more, but special instructions have been given to R to only print out a special digested version of the object. This behaviour tends to be true with model objects in general, not just for `lm()`.

## Probing the model: Broom

Now that you have the model object, there are typically three ways in which it's useful to probe and use the model object. The `broom` package has three crown functions that make it easy to extract each piece of information by converting your model into a tibble. 

### `tidy()`

Use the `tidy()` function for a statistical summary of each component of your model, where each component gets a row in the output tibble. For `lm()`, `tidy()` gives one row per regression coefficient (slope and intercept).

```{r}
tidy(my_lm)
```

`tidy()` only works if it makes sense to talk about model "components".

### `augment()`

Use the `augment()` function to make predictions on a dataset by augmenting predictions as a new column to your data. By default, `augment()` uses the dataset that was used to fit the model.

```{r}
augment(my_lm) %>% 
  print(n = 5)
```

We can also predict on new datasets. Here are predictions of `mpg` for cars weighing 3, 4, and 5 thousand lbs. 

```{r, warning = FALSE}
augment(my_lm, newdata = tibble(wt = 3:5))
```

Notice that only the "X" variables are needed in the input tibble (`wt`), and that since the "Y" variable (`mpg`) wasn't provided, `augment()` couldn't calculate anything besides a prediction.

### `glance()`

Use the `glance()` function to extract a summary of the model as a whole, in the form of a one-row tibble. This will give you information related to the model fit.

```{r}
glance(my_lm)
```


## Probing the Model: Traditional Method

In order for a model to work with the `broom` package, someone has to go out of their way to contribute to the `broom` package for that model. While this has happened for many common models, many others remain without `broom` compatibility.

Here's how to work with these model objects in that case.

### Prediction

If `broom::augment()` doesn't work, then the developer of the model almost surely made it so that the `predict()` function works (not part of the `broom` package). The `predict()` function typically takes the same format of the `augment()` function, but usually doesn't return a tibble.

Here are the first 5 predictions of mpg on the `my_lm` object, defaulting to predictions made on the original data:

```{r}
predict(my_lm) %>% 
  unname() %>% 
  head(5)
```

Here are the predictions of mpg made for cars with a weight of 3, 4, and 5 thousand lbs:

```{r}
predict(my_lm, newdata = tibble(wt = 3:5)) %>% 
  unname()
```

Checking the documentation of the `predict()` function _for your model_ isn't obvious, because the `predict()` function is a "generic" function. Your best bet is to append the model name after a dot. For example:

- For a model fit with `lm()`, try `?predict.lm`
- For a model fit with `rq()`, try `?predict.rq` (from the `quantreg` package)

If that doesn't work, just google it: `"Predict function for rq"`

### Functions designed for the model

The developer of the model probably made a suite of other functions to help you probe the model object. Check the documentation to find these.

For example, I can find the regression coefficients of a `lm()` object with `coef()`:

```{r}
coef(my_lm)
```

Standard error of the residuals with `sigma()`:

```{r}
sigma(my_lm)
```

Don't be surprised if there is no function to extract what you want. If that's the case, read on...

### Manually Extracting Information

If you can't extract model information from built-in functions like `coef()` or `sigma()`, you can manually dig in to the model object. In most cases, a model object is just a list in disguise! (Lists are discussed in STAT 545B). You can therefore extract information like you would with any other list.

To help figure out what's in the list, use the `names()` function. Here are all the entries in the `lm()` object we fit earlier:

```{r}
names(my_lm)
```

Want the degrees of freedom of the residuals? Just extract that entry:

```{r}
my_lm$df.residual
```

To complicate things further this might only be _part_ of the information made available in the model object! More info might be stored in _yet another_ list after applying the `summary()` function:

```{r}
summary(my_lm)
```

Like the original model object, `summary()` _looks_ like it returns a bunch of text -- but it's actually another list! Let's again use `names()` to get the components of this list:

```{r}
names(summary(my_lm))
```

Now I can get more pieces of information, like the adjusted R-squared value:

```{r}
summary(my_lm)$adj.r.squared
```



# Victor's Notes

Topics for today's demo:

- fitting a linear regression model using `lm`
- how to extract modelling information using the package `broom`
- plotting models using `geom_smooth`

```{r}
library(tidyverse)
library(gapminder)
library(broom)
```

### What is Model-Fitting? 

A way to test if there is a "relationship" between two or more variables

Let's look at dataset `mtcars` as an example:

```{r}
ggplot(mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  labs(x = "Weight (1000's of lbs)")
```

1. Is there a relationship between `wt` (car weight) and `mpg` (fuel efficiency)?

2. Or another way to ask, does car weight have some information that tells us about fuel efficiency?

Modelling is a way to quantify this relationship. 

### Fitting a model in R

Most model fitting functions have a common format:

```
function(formula, data, options)
```

1. **Formula** 

- describes the relationship you want to test (e.g. `wt ~ mpg`)
- Formulas look like this: `y ~ x1 + x2 + ...`

2. **data** 

- the `data.frame`/`tibble` that contains your variables
- can omit, if variables in formula are defined in environment

e.g. 
```{r}
y1 <- c(1,2,3)
x1 <- c(0.1, 0.2, 0.3)
lm(y1~x1)

# same as
d1 <- tibble(y1 = y1, x1 = x1) # store y1 and x2 into tibble
rm(y1, x1)                     # remove y1 and x2 from environment
lm(y1~x1, data = d1)           
```


3. **options** 

- ways to customize the model
- specific to each type of model

The output of these is usually a **special _list_** object.

```{r}
my_model <- lm(y1~x1, data = d1) 
str(my_model)
```

Some model functions in R:

- Linear Regression: `lm`
- Generalized Linear Regression: `glm`
- Local regression: `loess`
- Quantile regression: `quantreg::rq`
- ...

Let's fit a linear model with between `wt` and `mpg` in the `mtcars` dataset:

```{r}
(my_lm <- lm(mpg ~ wt, data = mtcars))
```


### `predict()`

**Functions:** `broom::augment()` and `predict()`

We can use the `predict()` or `broom::augment()` to make predictions from the model (default is to use fitting/training data). 

```{r predict-training}
predict(my_lm) %>% 
  head()
```


```{r augment-training}
augment(my_lm)
```


Or we can predict on a new dataset:

```{r predict-newdata}
wt1 <- tibble(wt = seq(18:23))
wt1

predict(my_lm,wt1)
```

```{r augment-newdata}
augment(my_lm, newdata = wt1)

wt1 %>%
  mutate(mpg = c(32, 26, 20, 14, 8, 2)) %>%
  augment(my_lm, newdata = .)
```
### `summary()`

`lm` output lacks information:

```{r}
my_lm
```

To get more information, we can use `summary`:

```{r}
summary(my_lm)
```

`summary` is useful for reading, but it's not easy to work with this output

### Introduce `broom::tidy`

- extracts statistical summaries for each component of the model
- returns in tabular format
- useful for _interpretation_

```{r}
tidy(my_lm)
```

```{r}
coef(summary(my_lm)) 
```

### `broom::glance`

- gives statistical summary on model as a whole
- useful for checking goodness of fit

```{r}
glance(my_lm)
```


### Plotting linear models with `geom_smooth`

We can plot models (with one predictor/ X variable) using `ggplot2` through the `geom_smooth()` layer. Specifying `method="lm"` gives us the linear regression fit (but only visually!):

```{r}
ggplot(mtcars, aes(x = wt, y = mpg)) +
    #geom_point() +
    geom_smooth(method="lm") 
```

Let's visualize some relationships in the `gapminder` dataset.

Lets the country "Zimbabwe", which has a unique behavior in the `lifeExp` and `year` relationship.

```{r}
gapminder_Zimbabwe <- gapminder %>% 
  filter(country == "Zimbabwe")

gapminder_Zimbabwe %>% 
  ggplot(aes(year, lifeExp)) + 
  geom_point()
```
Let's try fitting a linear model to this relationship
```{r}
ggplot(gapminder_Zimbabwe, aes(year,lifeExp)) +
  geom_point() +
  geom_smooth(method = "lm", se = F)
```
Now we will try to fit a second degree polynomial and see what would that look like.

```{r}
ggplot(gapminder_Zimbabwe, aes(year,lifeExp)) +
  geom_point() +
  geom_smooth(method = "lm",
              formula = y~poly(x,2), 
              se = F)
#?geom_smooth
```

### Summary

1. `function(formula, data, options)` - most models in R follow this structure.

2. `broom::augment()` - uses a fitted model to obtain predictions. Puts this in a new column in existing `tibble`. Equivalent base-r function is `predict()`.

3. `broom::tidy()` - used to extract statistical information on each component of a model. Equivalent is `coef(summary(lm_object))`.

4. `broom::glance()` - used to extract statistical summaries on the whole model. Always returns a 1-row `tibble`.

5. `geom_smooth()` - used to add geom_layer that shows a fitted line to the data. `method` and `formula` arguments can be used to customize model.

# (Taken from the worksheet)

So you want to fit a model to your data. How can you achieve this with R?

Topics:

1. What _is_ model-fitting?
2. How do we fit a model in R?
3. How can we obtain tidy results from the model output?

### What is Model-Fitting?
When variables are not independent, then we can gain information about one variable if we know something about the other.

Examples: Use the scatterplot below:

1. A car weighs 4000 lbs. What can we say about its mpg?
2. A car weights less than 3000 lbs. What can we say about its mpg?

Run the code cell below to see the `mtcars` plot.

```{r}
# models can fit many data points (using an 'averaged' data line is not always helpful)
ggplot(mtcars, aes(wt, mpg)) +
  geom_point() +
  labs(x = "Weight (1000's of lbs)")
```

Example: What can we say about rear axle ratio if we know something about quarter mile time? Run the code cell below!

```{r}
ggplot(mtcars, aes(qsec, drat)) + 
  geom_point() +
  labs(x = "Quarter mile time",
       y = "Rear axle ratio")
```

If EDA isn't enough, we can answer these questions by fitting a model: a curve that predicts Y given X. Aka, a __regression curve__ or a __machine learning model__. 

(There are more comprehensive models too, such as modelling entire distributions, but that's not what we're doing here)

There are typically two goals of fitting a model:

1. Make predictions.
2. Interpret variable relationships.

## Fitting a model in R

Model fitting methods tend to use a common format in R:

```
method(formula, data, options)
```

They also tend to have a common output: a special _list_. 

__Method__:

A function such as:

- Linear Regression: `lm`
- Generalized Linear Regression: `glm`
- Local regression: `loess`
- Quantile regression: `quantreg::rq`
- ...

__Formula__:

In R, takes the form `y ~ x1 + x2 + ... + xp` (use column names in your data frame).

__Data__: The data frame.

__Options__: Specific to the method.

# More stuff from the worksheet

However, to make things more complicated, some info is stored in _another_ list after applying the `summary` function. Run the code cell below.

```{r}
summary(answer3.3)
```

We can use the `predict()` function to make predictions from the model (default is to use fitting/training data). Here are the predictions. Run the code cell below. Use `predict()` to predict for years that are within our year range but do not have explicit data points.

```{r}
(gapminder_France <- data.frame(year = seq(2000, 2005)))
predict(answer3.3, newdata = gapminder_France) %>%
  head()
```

Or we can predict on a new dataset! Use `predict()` to predict for years that are beyond the range of our dataset, that is, extrapolate data using the model. Run the code cell below.

```{r}
years1 = data.frame(year = c(3000, 3005))
predict(answer3.3,years1)
plot(answer3.3)
```

We can plot models (with one predictor/ X variable) using `ggplot2` through the `geom_smooth()` layer. Specifying `method="lm"` gives us the linear regression fit (but only visually!). Run the code cell below.

```{r}
ggplot(gapminder, aes(gdpPercap, lifeExp)) +
    geom_point() +
    geom_smooth(method="lm") +
    scale_x_log10()
```

Let's consider another country "Zimbabwe", which has a unique behavior in the `lifeExp` and `year` relationship. Run the code cell below.

```{r}
gapminder_Zimbabwe <- gapminder %>%
  filter(country == "Zimbabwe")

gapminder_Zimbabwe %>% 
  ggplot(aes(year, lifeExp)) +
  geom_point()
```

Let's try fitting a linear model to this relationship. `se` option allows us to show or hide the confidence interval. Run the code cell below.

```{r}
ggplot(gapminder_Zimbabwe, aes(year,lifeExp)) +
  geom_point() +
  geom_smooth(method = "lm", se = F)
```

Now we will try to fit a second degree polynomial (`degree = 2`) and see what would that look like. Run the code cell below.

```{r}
ggplot(gapminder_Zimbabwe, aes(year, lifeExp)) + 
  geom_point()+
  geom_smooth(method = "lm", formula = y ~ poly(I(x - 1952), degree = 2))
```

## Broom
Let's make it easier to extract info, using the `broom` package. There are three crown functions in this package, all of which input a fitted model, and outputs a tidy data frame.

1. `tidy`: extract statistical summaries about each component of the model.
    - Useful for _interpretation_ task.
2. `augment`: add columns to the original data frame, giving information corresponding to each row.
    - Useful for _prediction_ task.
3. `glance`: extract statistical summaries about the model as a whole (1-row tibble).
    - Useful for checking goodness of fit.
    

## Attribution

- Fall 2020: Victor Yuan put this demonstration together. 